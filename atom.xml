<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Hexo</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2023-06-14T06:57:56.000Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>musiyu</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>spark</title>
    <link href="http://example.com/wiki/spark/"/>
    <id>http://example.com/wiki/spark/</id>
    <published>2023-06-14T05:40:30.000Z</published>
    <updated>2023-06-14T06:57:56.000Z</updated>
    
    <content type="html"><![CDATA[<p>（1）安装Anaconda</p><p>上传安装包 sh ./Anaconda3-2021.05-Linux-x86_64.sh</p><p><img src="/.com//clip_image002-16867215659061.png" alt="img"></p><p><img src="/.com//clip_image004-16867215659072.png" alt="img"></p><p>出现（base)即为安装成功</p><p>（2）创建虚拟环境</p><p>conda create -n pyspark python=3.8</p><p>conda activate pyspark</p><p>pip install pyhive pyspark jieba -i <a href="https://pypi.tuna.tsinghua.edu.cn/simple">https://pypi.tuna.tsinghua.edu.cn</a></p><p><a href="https://pypi.tuna.tsinghua.edu.cn/simple">/simple</a></p><p>（1）修改环境变量配置Spark由如下5个环境变量需要设置</p><p>SPARK_HOME: 表示Spark安装路径在哪里 </p><p>PYSPARK_PYTHON: 表示Spark想运行Python程序, 那么去哪里找python执行器。 </p><p>JAVA_HOME: 告知Spark Java在哪里 </p><p>HADOOP_CONF_DIR: 告知Spark Hadoop的配置文件在哪里 </p><p>HADOOP_HOME: 告知Spark Hadoop安装在哪里</p><p>这5个环境变量 都需要配置在: /etc/profile中！</p><p><img src="/.com//clip_image006.jpg" alt="img"></p><p>（4）解压</p><p>解压下载的Spark安装包</p><p>tar -zxvf spark-3.2.0-bin-hadoop3.2.tgz -C /export/server/<img src="/.com//clip_image008.jpg" alt="img"></p><p>设置软连接</p><p>ln -s /export/server/spark-3.2.0-bin-hadoop3.2 /export/server/spark</p><p>（2）测试</p><p>bin/pyspark</p><p><img src="/.com//clip_image010.jpg" alt="img">在这个环境可以运行spark代码，如图：</p><p><img src="/.com//clip_image012.jpg" alt="img"></p><p>sc.parallelize([1,2,3,4,5]).map(lambda x: x + 1).collect()</p><p><strong>Spark StandAlone**</strong>环境部署**</p><p>在所有机器安装Python(Anaconda)，并在所有机器配置环境变量。</p><p><img src="/.com//clip_image014-16867215659073.png" alt="img"></p><p><img src="/.com//clip_image016-16867215659074.png" alt="img"></p><p>（1）配置配置文件</p><p>进入到spark的配置文件目录中, cd $SPARK_HOME/conf`</p><p>配置workers文件vi workers</p><p># 改名, 去掉后面的.template后缀</p><p>mv workers.template workers</p><p># 编辑worker文件7</p><p>vim workers</p><p># 将里面的localhost删除, 追加</p><p>node1</p><p>node2</p><p>node3</p><p>到workers文件内</p><p><img src="/.com//clip_image018.jpg" alt="img">（2）配置spark-env.sh文件</p><p># 1. 改名</p><p>mv spark-env.sh.template spark-env.sh</p><p># 2. 编辑spark-env.sh, 在底部追加如下内容</p><p>## 设置JAVA安装目录</p><p>JAVA_HOME=/export/server/jdk</p><p>## HADOOP软件配置文件目录，读取HDFS上文件和运行YARN集群</p><p>HADOOP_CONF_DIR=/export/server/hadoop/etc/hadoop</p><p>YARN_CONF_DIR=/export/server/hadoop/etc/hadoop</p><p>## 指定spark老大Master的IP和提交任务的通信端口</p><p># 告知Spark的master运行在哪个机器上</p><p>export SPARK_MASTER_HOST=node1</p><p># 告知sparkmaster的通讯端口</p><p>export SPARK_MASTER_PORT=7077</p><p># 告知spark master的 webui端口</p><p>SPARK_MASTER_WEBUI_PORT=8080</p><p># worker cpu可用核数</p><p>SPARK_WORKER_CORES=1</p><p># worker可用内存</p><p>SPARK_WORKER_MEMORY=1g</p><p># worker的工作通讯地址</p><p>SPARK_WORKER_PORT=7078</p><p># worker的 webui地址</p><p>SPARK_WORKER_WEBUI_PORT=8081</p><p>## 设置历史服务器</p><p># 配置的意思是 将spark程序运行的历史日志 存到hdfs的/sparklog文件夹中</p><p><img src="/.com//clip_image020.jpg" alt="img">SPARK_HISTORY_OPTS=”-Dspark.history.fs.logDirectory=hdfs://node1:8020/sparklog/ -Dspark.history.fs.cleaner.enabled=true”</p><p>在HDFS上创建程序运行历史记录存放的文件夹:</p><p>hadoop fs -mkdir /sparklog</p><p><img src="/.com//clip_image022.jpg" alt="img">hadoop fs -chmod 777 /sparklog</p><p>（3）配置spark-defaults.conf文件</p><p># 1. 改名</p><p>mv spark-defaults.conf.template spark-defaults.conf</p><p># 2. 修改内容, 追加如下内容</p><p># 开启spark的日期记录功能</p><p>spark.eventLog.enabled  true</p><p># 设置spark日志记录的路径</p><p>spark.eventLog.dir   hdfs://node1:8020/sparklog/ </p><p># 设置spark日志是否启动压缩</p><p>spark.eventLog.compress  true</p><p><img src="/.com//clip_image024.jpg" alt="img">（4）配置log4j.properties 文件 [可选配置]</p><p>mv log4j.properties.template log4j.properties</p><p><img src="/.com//clip_image026.jpg" alt="img">注意：将Spark安装文件夹  分发到其它的服务器</p><p>1）scp -r spark-3.1.2-bin-hadoop3.2 node2:/export/server/</p><p>2）scp -r spark-3.1.2-bin-hadoop3.2 node3:/export/server/</p><p>3）在node2和node3上 给spark安装目录增加软链接</p><p>ln -s /export/server/spark-3.2.0-bin-hadoop3.2 /export/server/spark</p><p><img src="/.com//clip_image028.jpg" alt="img"></p><p>（5）启动历史服务器</p><p>sbin/start-history-server.sh</p><p><img src="/.com//clip_image030.jpg" alt="img"></p><p>（6）启动Spark的Master和Worker进程</p><p>sbin/start-all.sh</p><p>sbin/start-master.sh</p><p>sbin/start-worker.sh</p><p>sbin/stop-all.sh</p><p>sbin/stop-master.sh</p><p>sbin/stop-worker.sh</p><p><img src="/.com//clip_image032.jpg" alt="img"><img src="/.com//clip_image034.jpg" alt="img"></p><p><img src="/.com//clip_image036.jpg" alt="img"></p><p>查看Master的WEB UI</p><p>连接到StandAlone集群</p><p><img src="/.com//clip_image038.jpg" alt="img"></p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><blockquote><ul><li><a href></a></li><li><a href></a></li></ul></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;（1）安装Anaconda&lt;/p&gt;
&lt;p&gt;上传安装包 sh ./Anaconda3-2021.05-Linux-x86_64.sh&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/.com//clip_image002-16867215659061.png&quot; alt=&quot;img&quot;&gt;&lt;/p</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>hive</title>
    <link href="http://example.com/wiki/hive/"/>
    <id>http://example.com/wiki/hive/</id>
    <published>2023-06-14T04:50:15.000Z</published>
    <updated>2023-06-14T05:33:08.000Z</updated>
    
    <content type="html"><![CDATA[<p><strong>1**</strong>）<strong><strong>Mysql</strong></strong>安装**</p><p>1）卸载Centos7自带的mariadb</p><p><img src="../images/clip_image002.png" alt></p><p>如果出现了mariadb-libs-5.5.64-1.el7.x86_64，输入rpm -e mariadb- libs-5.5.64-1.el7.x86_64 –nodeps,在输入rpm -qa|grep mariadb，即可</p><p>2）安装mysql</p><p>新建文件夹：mkdir /export/server/mysql</p><p>上传mysql-5.7.29-1.el7.x86_64.rpm-bundle.tar到上述文件夹下，解压tar xvf mysql-5.7.29-1.el7.x86_64.rpm-bundle.tar</p><p><img src="../images/clip_image004.png" alt></p><p>3）执行安装</p><p>yum -y install libaio</p><p><img src="../images/clip_image006.png" alt></p><p><img src="../images/clip_image008.png" alt></p><p>4）mysql初始化设置</p><p>初始化：mysqld –initialize</p><p>更改所属组：chown mysql:mysql /var/lib/mysql -R</p><p>启动mysql：systemctl start mysqld.service</p><p><img src="../images/clip_image010.png" alt></p><p>查看临时生成的root密码：cat /var/log/mysqld.log</p><p><img src="../images/clip_image012.png" alt></p><p>5）修改root密码 授权远程访问 设置开机自启动</p><p><img src="../images/clip_image014.png" alt></p><p>修改root密码 设置为hadoop</p><p><img src="../images/clip_image016.png" alt></p><p>授权</p><p>use mysql;</p><p>GRANT ALL PRIVILEGES ON <em>.</em> TO ‘root‘@’%’ IDENTIFIED BY ‘hadoop’ WITH GRANT OPTION;</p><p>FLUSH PRIVILEGES;</p><p><img src="../images/clip_image018.png" alt></p><p>mysql的启动和关闭 状态查看 （这几个命令必须记住）</p><p>systemctl stop mysqld</p><p>systemctl status mysqld</p><p>systemctl start mysqld</p><p>设置开机自动启动：systemctl enable mysqld </p><p>查看是否设置自动启动成功</p><p><img src="../images/clip_image020.png" alt></p><p><strong>（**</strong>2<strong><strong>）</strong></strong>Hive<strong>**的安装</strong></p><p>1）上传安装包 解压</p><p>tar zxvf apache-hive-3.1.2-bin.tar.gz</p><p>ln -s apache-hive-3.1.2-bin hive</p><p>2）解决Hive与Hadoop之间guava版本差异</p><p>cd /export/server/hive/</p><p>rm -rf lib/guava-19.0.jar</p><p>cp /export/server/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar</p><p> ./lib/</p><p><img src="../images/clip_image022.png" alt></p><p>3）修改配置文件</p><p>hive-env.sh</p><p>cd /export/server/hive/conf</p><p>mv hive-env.sh.template hive-env.sh</p><p>vim hive-env.sh</p><p>export HADOOP_HOME=/export/server/hadoop</p><p>export HIVE_CONF_DIR=/export/server/hive/conf</p><p>export HIVE_AUX_JARS_PATH=/export/server/hive/lib</p><p><img src="../images/clip_image024.png" alt></p><p><img src="../images/clip_image026.png" alt></p><p>hive-site.xml</p><p>vim hive-site.xml</p><configuration><br><br><!-- 存储元数据mysql相关配置 --><br><br><property><br><br>​    <name>javax.jdo.option.ConnectionURL</name><br><br>​    <value>jdbc:mysql://node1:3306/hive3?createDatabaseIfNotExist=true&amp;useSSL=false&amp;useUnicode=true&amp;characterEncoding=UTF-8</value><br><br></property><br><br><property><br><br>​    <name>javax.jdo.option.ConnectionDriverName</name><br><br>​    <value>com.mysql.jdbc.Driver</value><br><br></property><br><br><property><br><br>​    <name>javax.jdo.option.ConnectionUserName</name><br><br>​    <value>root</value><br><br></property><br><br><property><br><br>​    <name>javax.jdo.option.ConnectionPassword</name><br><br>​    <value>hadoop</value><br><br></property><br><br><!-- H2S运行绑定host --><br><br><property><br><br>  <name>hive.server2.thrift.bind.host</name><br><br>  <value>node1</value><br><br></property><br><br><!-- 远程模式部署metastore metastore地址 --><br><br><property><br><br>  <name>hive.metastore.uris</name><br><br>  <value>thrift://node1:9083</value><br><br></property><br><br><!-- 关闭元数据存储授权 --><br><br><property><br><br>  <name>hive.metastore.event.db.notification.api.auth</name><br><br>  <value>false</value><br><br></property><br><br></configuration><p>4）上传mysql jdbc驱动到hive安装包lib下</p><p>mysql-connector-java-5.1.32.jar</p><p><img src="../images/clip_image028.png" alt></p><p>5）初始化元数据</p><p>cd /export/server/hive/</p><p>bin/schematool -initSchema -dbType mysql -verbos</p><p>初始化成功之后会在MySQL中创建74张表</p><p><img src="../images/clip_image030.png" alt></p><p>6）在hdfs创建hive存储目录（如存在则不用操作）</p><p>hadoop fs -mkdir /tmp</p><p>hadoop fs -mkdir -p /user/hive/warehouse</p><p>hadoop fs -chmod g+w /tmp</p><p>hadoop fs -chmod g+w /user/hive/warehouse</p><p>7）启动hive</p><p><strong>（**</strong>3<strong><strong>）启动</strong></strong>metastore<strong>**服务</strong> 前台启动 关闭ctrl+c</p><p>/export/server/hive/bin/hive –service metastore</p><p><img src="../images/clip_image032.png" alt></p><p>前台启动开启debug日志</p><p>/export/server/hive/bin/hive –service metastore –hiveconf hive.root.logger=DEBUG,console </p><p><img src="../images/clip_image034.png" alt></p><p>后台启动 进程挂起 关闭使用jps+ kill -9</p><p>nohup /export/server/hive/bin/hive –service metastore &amp;</p><p><img src="../images/clip_image036.png" alt></p><p><strong>（**</strong>4<strong><strong>）启动</strong></strong>hiveserver2<strong>**服务</strong></p><p>nohup /export/server/hive/bin/hive –service hiveserver2 &amp;</p><p><img src="../images/clip_image038.png" alt></p><p><img src="../images/clip_image040.png" alt></p><p>beeline客户端连接</p><p>拷贝node1安装包到beeline客户端机器上（node3）</p><p>scp -r /export/server/apache-hive-3.1.2-bin/ root@node3:/export/server/</p><p><strong>（**</strong>5<strong><strong>）</strong></strong>hive<strong>**注释信息中文乱码解决</strong></p><p>以下sql语句均在mysql数据库中执行</p><p>use hivenode2;</p><p>show tables;</p><p>alter table hivenode2.COLUMNS_V2 modify column COMMENT varchar(256) character set utf8;</p><p>alter table hivenode2.TABLE_PARAMS modify column PARAM_VALUE varchar(4000) character set utf8;</p><p>alter table hivenode2.PARTITION_PARAMS modify column PARAM_VALUE varchar(4000) character set utf8 ;</p><p>alter table hivenode2.PARTITION_KEYS modify column PKEY_COMMENT varchar(4000) character set utf8;</p><p>alter table hivenode2.INDEX_PARAMS modify column PARAM_VALUE varchar(4000) character set utf8;</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><blockquote><ul><li><a href></a></li><li><a href></a></li></ul></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;1**&lt;/strong&gt;）&lt;strong&gt;&lt;strong&gt;Mysql&lt;/strong&gt;&lt;/strong&gt;安装**&lt;/p&gt;
&lt;p&gt;1）卸载Centos7自带的mariadb&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../images/clip_image002.pn</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>git</title>
    <link href="http://example.com/wiki/git/"/>
    <id>http://example.com/wiki/git/</id>
    <published>2023-06-14T04:47:29.000Z</published>
    <updated>2023-06-14T05:37:32.000Z</updated>
    
    <content type="html"><![CDATA[<p>（1）Git下载</p><p>核心程序</p><p><img src="/.com//images2/clip_image002.jpg" alt></p><p>（2）可视化客户端</p><p><img src="/.com//images2/clip_image003.png" alt></p><p>中文语言包</p><p><img src="/.com//images2/clip_image005.jpg" alt></p><p>（3）初始化仓库</p><p><img src="/.com//images2/clip_image006.png" alt></p><p><img src="/.com//images2/clip_image008.jpg" alt></p><p>（4）添加文件，提交文件至本地仓库</p><p><img src="/.com//images2/clip_image010.jpg" alt></p><p>（5）本地删除与恢复</p><p>文件选中删除，可用以下方式还原</p><p><img src="/.com//images2/clip_image012.jpg" alt></p><p>（6）创建分支</p><p><img src="/.com//images2/clip_image014.jpg" alt></p><p><img src="/.com//images2/clip_image016.jpg" alt></p><p>（7）分支的查看切换</p><p><img src="/.com//images2/clip_image018.jpg" alt></p><p><img src="/.com//images2/clip_image020.jpg" alt><img src="/.com//images2/clip_image022.jpg" alt></p><p>（8）标签的创建</p><p><img src="/.com//images2/clip_image024.jpg" alt></p><p><img src="/.com//images2/clip_image026.jpg" alt></p><p>（9）切换与删除</p><p><img src="/.com//images2/clip_image028.png" alt></p><p><img src="/.com//images2/clip_image030.png" alt></p><p>通过右键选中删除</p><p><strong>远程仓库</strong></p><p><img src="/.com//images2/clip_image032.jpg" alt></p><p><img src="/.com//images2/clip_image034.jpg" alt></p><p>（1）码云账号注册</p><p><img src="/.com//images2/clip_image036.jpg" alt></p><p>填写邮箱发送验证码,然后可以注册账号,主页如下</p><p><img src="/.com//images2/clip_image038.jpg" alt></p><p>（2）创建远程仓库</p><p><img src="/.com//images2/clip_image040.jpg" alt></p><p>（3）把本地代码推送到远端</p><p><img src="/.com//images2/clip_image042.jpg" alt></p><p><img src="/.com//images2/clip_image044.jpg" alt></p><p>生成公钥私钥</p><p>ssh-keygen -t rsa</p><p>一直回车</p><p>会默认用户目录 .ssh 目录生成一个默认的id_rsa文件 和id_rsa.pub</p><p>密钥配置</p><p><img src="/.com//images2/clip_image046.jpg" alt></p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><blockquote><ul><li><a href></a></li><li><a href></a></li></ul></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;（1）Git下载&lt;/p&gt;
&lt;p&gt;核心程序&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/.com//images2/clip_image002.jpg&quot; alt&gt;&lt;/p&gt;
&lt;p&gt;（2）可视化客户端&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/.com//images2/clip_image0</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://example.com/wiki/hello-world/"/>
    <id>http://example.com/wiki/hello-world/</id>
    <published>2023-06-08T02:21:40.060Z</published>
    <updated>2023-06-08T02:21:42.000Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.io/docs/&quot;&gt;documentation&lt;/a&gt; for</summary>
      
    
    
    
    
  </entry>
  
</feed>
